{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Classifying Dogs and Cats with a VGG-16 model**\n\nOriginal dataset : [Cats-vs-Dogs : image dataset for binary classification](https://www.kaggle.com/shaunthesheep/microsoft-catsvsdogs-dataset)\n*** \n\n# **Introduction** \n\nA pre-trained ConvNet is composed of two parts :\n* the **convolutional base** (convolutions + poolings)\n* the **classifier** (fully connected network).\n\nWe keep the convolutional base, which probably has the most generic informations.  \n\nWe change the classifier to adapt to the problem we have to deal with. \n\n***","metadata":{}},{"cell_type":"code","source":"# Libraries\nimport os, shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\nfrom keras import layers\nfrom keras import models, optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.applications.vgg16 import VGG16","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:03:38.629836Z","iopub.execute_input":"2021-12-16T07:03:38.630185Z","iopub.status.idle":"2021-12-16T07:03:43.769294Z","shell.execute_reply.started":"2021-12-16T07:03:38.630073Z","shell.execute_reply":"2021-12-16T07:03:43.768495Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"***\n\n# **Data**\n\n* Whole dataset : around 25,000 images (around 12,500 of each class)\n  \n* We use just a small part of those images. \n\n* Steps \n  * Load the dataset\n  * Create 3 sets :\n    * a training set with 1000 images\n    * a validation set with 500 images\n    * a test set with 500 images.\n\n* Functions we use :\n  * os.mkdir() : create a new folder\n  * os.path.join(path, string) : add the string to the path\n  * shutil.copyfile(source, destination) : copy the file from the source to the destination.","metadata":{}},{"cell_type":"code","source":"# path to the folder where the whole dataset is stored\noriginal_dataset_dir = '../input/microsoft-catsvsdogs-dataset/PetImages'\n\n# create a folder to store our small sample of images\nbase_dir = '../cats_and_dogs_small'\nos.mkdir(base_dir)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:03:43.771319Z","iopub.execute_input":"2021-12-16T07:03:43.771612Z","iopub.status.idle":"2021-12-16T07:03:43.779438Z","shell.execute_reply.started":"2021-12-16T07:03:43.771569Z","shell.execute_reply":"2021-12-16T07:03:43.775749Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# create sub-folders for training, validation and test sets\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\n\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\n\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\n\n# create sub-folders Cat and Dog \ntrain_Cat_dir = os.path.join(train_dir, 'Cat')\nos.mkdir(train_Cat_dir)\n\ntrain_Dog_dir = os.path.join(train_dir, 'Dog')\nos.mkdir(train_Dog_dir)\n\nvalidation_Cat_dir = os.path.join(validation_dir, 'Cat')\nos.mkdir(validation_Cat_dir)\n\nvalidation_Dog_dir = os.path.join(validation_dir, 'Dog')\nos.mkdir(validation_Dog_dir)\n\ntest_Cat_dir = os.path.join(test_dir, 'Cat')\nos.mkdir(test_Cat_dir)\n\ntest_Dog_dir = os.path.join(test_dir, 'Dog')\nos.mkdir(test_Dog_dir)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:03:43.780844Z","iopub.execute_input":"2021-12-16T07:03:43.781539Z","iopub.status.idle":"2021-12-16T07:03:43.793323Z","shell.execute_reply.started":"2021-12-16T07:03:43.781439Z","shell.execute_reply":"2021-12-16T07:03:43.792488Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# copy images from the whole dataset to different folders :\n\n# copy the first 1000 cats images to the folder train_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '/Cat', fname)\n    dst = os.path.join(train_Cat_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# copy the following 500 cats images to the folder validation_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '/Cat', fname)\n    dst = os.path.join(validation_Cat_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copy the following 500 cats images to the folder test_dir    \nfnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '/Cat', fname)\n    dst = os.path.join(test_Cat_dir, fname)\n    shutil.copyfile(src, dst)\n\n    \n# copy the first 1000 dogs images to the folder train_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '/Dog', fname)\n    dst = os.path.join(train_Dog_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# copy the following 500 dogs images to the folder validation_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '/Dog', fname)\n    dst = os.path.join(validation_Dog_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copy the following 500 dogs images to the folder test_dir    \nfnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '/Dog', fname)\n    dst = os.path.join(test_Dog_dir, fname)\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:03:43.794746Z","iopub.execute_input":"2021-12-16T07:03:43.795078Z","iopub.status.idle":"2021-12-16T07:04:10.469773Z","shell.execute_reply.started":"2021-12-16T07:03:43.795033Z","shell.execute_reply":"2021-12-16T07:04:10.469034Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# quick check\nprint(\"total training cat images :\", len(os.listdir(train_Cat_dir)))\nprint(\"total training dog images :\", len(os.listdir(train_Dog_dir)))\nprint(\"total validation cat images :\", len(os.listdir(validation_Cat_dir)))\nprint(\"total validation dog images :\", len(os.listdir(validation_Dog_dir)))\nprint(\"total test cat images :\", len(os.listdir(test_Cat_dir)))\nprint(\"total test dog images :\", len(os.listdir(test_Dog_dir)))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:04:10.472199Z","iopub.execute_input":"2021-12-16T07:04:10.472471Z","iopub.status.idle":"2021-12-16T07:04:10.488957Z","shell.execute_reply.started":"2021-12-16T07:04:10.472435Z","shell.execute_reply":"2021-12-16T07:04:10.488108Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# size of an image\nimg = cv2.imread(train_Cat_dir + '/' + os.listdir(train_Cat_dir)[0])\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:04:10.490280Z","iopub.execute_input":"2021-12-16T07:04:10.490653Z","iopub.status.idle":"2021-12-16T07:04:10.520103Z","shell.execute_reply.started":"2021-12-16T07:04:10.490608Z","shell.execute_reply":"2021-12-16T07:04:10.519211Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# error in data\n# We just replace 666.jpg by 665.jpg\nshutil.copyfile(train_Cat_dir + '/665.jpg', train_Cat_dir + '/666.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:04:10.521505Z","iopub.execute_input":"2021-12-16T07:04:10.521857Z","iopub.status.idle":"2021-12-16T07:04:10.529384Z","shell.execute_reply.started":"2021-12-16T07:04:10.521815Z","shell.execute_reply":"2021-12-16T07:04:10.528418Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"***\n\n# **Load a pre-trained model**\n\nWe use **VGG16()**, with arguments :\n* weights : from the training on the dataset ImageNet (1.4 millions of images, 1000 classes)\n* include_top : include or not the top part of the network, the fully-connected one\n* input_shape.\n\nNB : error when downloading the model \n* [forum kaggle](https://www.kaggle.com/questions-and-answers/128824#735972)\n* [forum kaggle](https://www.kaggle.com/getting-started/40246)\n* first : 'Add Data' >> 'vgg16' ","metadata":{}},{"cell_type":"code","source":"conv_base = VGG16(weights='../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(150,150,3))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:04:10.531058Z","iopub.execute_input":"2021-12-16T07:04:10.531506Z","iopub.status.idle":"2021-12-16T07:04:13.391244Z","shell.execute_reply.started":"2021-12-16T07:04:10.531467Z","shell.execute_reply":"2021-12-16T07:04:13.390498Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"conv_base.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:04:13.392772Z","iopub.execute_input":"2021-12-16T07:04:13.393315Z","iopub.status.idle":"2021-12-16T07:04:13.411834Z","shell.execute_reply.started":"2021-12-16T07:04:13.393273Z","shell.execute_reply":"2021-12-16T07:04:13.410918Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"***\n\n# **Method 1 : without Data Augmentation**\n\nSteps :\n* use the pre-trained model to extract the features\n* resize the output so that it can used by the classifier\n* train the new classifier\n* evaluate. \n\n\n## Extract the features with the convolutional base\n\nWe use the class **ImageDataGenerator()**. ","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1./255)\nbatch_size = 20\n\n''' Function 'extract_feature()'\n* inputs : \n  * 'directory' : folder containing the images (train_dir, validation_dir or test_dir)\n  * 'sample_count' : number of images in the directory (2000 or 1000)\n* outputs :\n  * 'features' : features extracted, each with the format (4, 4, 512) \n  * 'labels' : labels of the images. \n'''\n\ndef extract_feature(directory, sample_count):\n    # initialize the arrays 'features' and 'labels' with zeros\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count,))\n    # apply the generator to the directory \n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150,150),\n        batch_size=batch_size,\n        class_mode='binary'\n    )\n    # use the convolutional base on the generated images (.predict())\n    # add the extracted features and the generated labels to the arrays 'features' et 'labels'\n    # stop when all the images in the directory are treated\n    i=0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i*batch_size : (i+1)*batch_size] = features_batch \n        labels[i*batch_size : (i+1)*batch_size] = labels_batch\n        i += 1\n        if i*batch_size >= sample_count:\n            break\n    return features, labels\n\n# apply the function 'extract_feature()' to the 3 directories train_dir, validation_dir, test_dir\ntrain_features, train_labels = extract_feature(train_dir, 2000)\nvalidation_features, validation_labels = extract_feature(validation_dir, 1000)\ntest_features, test_labels = extract_feature(test_dir, 1000)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:04:13.413802Z","iopub.execute_input":"2021-12-16T07:04:13.414669Z","iopub.status.idle":"2021-12-16T07:04:50.433799Z","shell.execute_reply.started":"2021-12-16T07:04:13.414630Z","shell.execute_reply":"2021-12-16T07:04:50.433084Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Resize the extracted features\n\nThe extracted features have the format (samples, 4, 4, 512) : we flatten them into the format (samples, 4x4x512).","metadata":{}},{"cell_type":"code","source":"train_features = np.reshape(train_features, (2000, 4*4*512))\nvalidation_features = np.reshape(validation_features, (1000, 4*4*512))\ntest_features = np.reshape(test_features, (1000, 4*4*512))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:04:50.435245Z","iopub.execute_input":"2021-12-16T07:04:50.435485Z","iopub.status.idle":"2021-12-16T07:04:50.441027Z","shell.execute_reply.started":"2021-12-16T07:04:50.435452Z","shell.execute_reply":"2021-12-16T07:04:50.439889Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Define the new classifier","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\n\nmodel.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',  # optimizers.RMSprop(lr=1e-4) ??\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:04:50.442063Z","iopub.execute_input":"2021-12-16T07:04:50.442318Z","iopub.status.idle":"2021-12-16T07:04:50.482416Z","shell.execute_reply.started":"2021-12-16T07:04:50.442285Z","shell.execute_reply":"2021-12-16T07:04:50.481785Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Train the classifier","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n            train_features, train_labels,\n            epochs=30, \n            batch_size=20,\n            validation_data=(validation_features, validation_labels)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:04:50.483542Z","iopub.execute_input":"2021-12-16T07:04:50.483785Z","iopub.status.idle":"2021-12-16T07:05:11.505433Z","shell.execute_reply.started":"2021-12-16T07:04:50.483751Z","shell.execute_reply":"2021-12-16T07:05:11.504268Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# save the trained model\nmodel.save('classifying_cats_dogs_small_3.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:05:11.509053Z","iopub.execute_input":"2021-12-16T07:05:11.509368Z","iopub.status.idle":"2021-12-16T07:05:11.548485Z","shell.execute_reply.started":"2021-12-16T07:05:11.509333Z","shell.execute_reply":"2021-12-16T07:05:11.547767Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate the model","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'bo', label='training')\nplt.plot(epochs, val_acc, 'b', label='validation')\nplt.title(\"Training and Validation Accuracy\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='training')\nplt.plot(epochs, val_loss, 'b', label='validation')\nplt.title(\"Training and Validation Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:05:11.549889Z","iopub.execute_input":"2021-12-16T07:05:11.550241Z","iopub.status.idle":"2021-12-16T07:05:11.995392Z","shell.execute_reply.started":"2021-12-16T07:05:11.550203Z","shell.execute_reply":"2021-12-16T07:05:11.994672Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"The accuracy is pretty good, around 90%, but the model is in overfitting from the beginning.","metadata":{}},{"cell_type":"markdown","source":"***\n\n# **Method 2 : with Data Augmentation**\n\nSteps :\n* generate the images with data augmentation\n* build the model with the convolution base and the new classifier together \n* freeze the convolutional base, don't need to be trained\n* train the model\n* evaluate.","metadata":{}},{"cell_type":"markdown","source":"## Generate the images with data augmentation","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2, \n                                  horizontal_flip=True, \n                                  fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                        train_dir,\n                        target_size=(150,150),\n                        batch_size=20,\n                        class_mode='binary' \n                        )\n\nvalidation_generator = test_datagen.flow_from_directory(\n                        validation_dir,\n                        target_size=(150,150),\n                        batch_size=20,\n                        class_mode='binary' \n                        )","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:05:11.996883Z","iopub.execute_input":"2021-12-16T07:05:11.997148Z","iopub.status.idle":"2021-12-16T07:05:12.215421Z","shell.execute_reply.started":"2021-12-16T07:05:11.997096Z","shell.execute_reply":"2021-12-16T07:05:12.214619Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Build the model","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\n\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\n#model.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:05:12.216532Z","iopub.execute_input":"2021-12-16T07:05:12.219315Z","iopub.status.idle":"2021-12-16T07:05:12.289492Z","shell.execute_reply.started":"2021-12-16T07:05:12.219259Z","shell.execute_reply":"2021-12-16T07:05:12.288695Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:05:12.290699Z","iopub.execute_input":"2021-12-16T07:05:12.290972Z","iopub.status.idle":"2021-12-16T07:05:12.300690Z","shell.execute_reply.started":"2021-12-16T07:05:12.290939Z","shell.execute_reply":"2021-12-16T07:05:12.299981Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Freeze the convolutional base","metadata":{}},{"cell_type":"code","source":"print(\"Number of trainable weights before freezing:\", len(model.trainable_weights))\nconv_base.trainable = False\nprint(\"Number of trainable weights after freezing:\", len(model.trainable_weights))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:05:12.301995Z","iopub.execute_input":"2021-12-16T07:05:12.302434Z","iopub.status.idle":"2021-12-16T07:05:12.309440Z","shell.execute_reply.started":"2021-12-16T07:05:12.302394Z","shell.execute_reply":"2021-12-16T07:05:12.308658Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Train the model","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='rmsprop',  # optimizers.RMSprop(lr=1e-4) ??\n             loss='binary_crossentropy',\n             metrics=['accuracy'])\n\nhistory = model.fit_generator(\n            train_generator,\n            #steps_per_epoch=100,     \n            epochs=30, \n            validation_data=validation_generator,\n            #validation_steps=50      \n)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:05:12.311176Z","iopub.execute_input":"2021-12-16T07:05:12.311624Z","iopub.status.idle":"2021-12-16T07:14:11.031595Z","shell.execute_reply.started":"2021-12-16T07:05:12.311536Z","shell.execute_reply":"2021-12-16T07:14:11.030757Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# save the trained model \nmodel.save('classifying_cats_dogs_small_4.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:14:11.033310Z","iopub.execute_input":"2021-12-16T07:14:11.033549Z","iopub.status.idle":"2021-12-16T07:14:11.166177Z","shell.execute_reply.started":"2021-12-16T07:14:11.033517Z","shell.execute_reply":"2021-12-16T07:14:11.165469Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the model","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'bo', label='training')\nplt.plot(epochs, val_acc, 'b', label='validation')\nplt.title(\"Training and Validation Accuracy\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='training')\nplt.plot(epochs, val_loss, 'b', label='validation')\nplt.title(\"Training and Validation Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:14:11.167638Z","iopub.execute_input":"2021-12-16T07:14:11.167982Z","iopub.status.idle":"2021-12-16T07:14:11.547893Z","shell.execute_reply.started":"2021-12-16T07:14:11.167935Z","shell.execute_reply":"2021-12-16T07:14:11.547205Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"###Accuracy is 90.8% , Performing binary classification where 0 stands for CAT and 1 stands for DOG","metadata":{}},{"cell_type":"code","source":"# make a prediction for a new image.\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import load_model\n\n# load and prepare the image\ndef load_image(filename):\n\t# load the image\n\timg = load_img(filename, target_size=(150, 150))\n\t# convert to array\n\timg = img_to_array(img)\n\t# reshape into a single sample with 3 channels\n\timg = img.reshape(1, 150, 150, 3)\n\t# center pixel data\n\timg = img.astype('float32')\n\t#img = img - [123.68, 116.779, 103.939]\n\treturn img\n\n# load an image and predict the class\ndef run_example():\n\t# load the image\n\timg = load_image('../input/microsoft-catsvsdogs-dataset/PetImages/Cat/1000.jpg')\n\t# load model\n\tmodel = load_model('classifying_cats_dogs_small_4.h5')\n\t# predict the class\n\tresult = model.predict(img)\n\tprint(result[0])\n\n# entry point, run the example\nrun_example()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:35:45.326315Z","iopub.execute_input":"2021-12-16T07:35:45.327124Z","iopub.status.idle":"2021-12-16T07:35:45.718174Z","shell.execute_reply.started":"2021-12-16T07:35:45.327085Z","shell.execute_reply":"2021-12-16T07:35:45.717400Z"},"trusted":true},"execution_count":32,"outputs":[]}]}
